# Fetal Heart Rate Hypoxia Detection System

**Multi-Method Deep Learning System for Fetal Heart Rate Analysis and Hypoxia Classification**

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Why This System Was Created](#why-this-system-was-created)
- [Dataset Information](#dataset-information)
- [Project Structure](#project-structure)
- [Deep Learning Methods](#deep-learning-methods)
- [Data Pipeline](#data-pipeline)
- [Installation](#installation)
- [Usage](#usage)
- [System Features](#system-features)
- [Technical Architecture](#technical-architecture)
- [Results and Performance](#results-and-performance)
- [Development Guide](#development-guide)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [References](#references)

---

## ğŸ¯ Overview

This system implements a comprehensive deep learning solution for detecting fetal hypoxia through analysis of Cardiotocography (CTG) signals, specifically Fetal Heart Rate (FHR) patterns. The system employs three different deep learning approaches to provide robust and accurate hypoxia classification.

### Key Features
- **Multi-Method Approach**: GAN data augmentation, MobileNet CNN, and ResNet deep learning
- **Simple Input**: Only requires CTG record number for prediction
- **Comprehensive Output**: Visual analysis, classification results, and confidence scores
- **Interactive Interface**: User-friendly CLI with multiple interface options
- **Production Ready**: Optimized for both research and clinical deployment

---

## ğŸ”¬ Why This System Was Created

### Medical Challenge
**Fetal hypoxia** is a critical condition during childbirth where the fetus doesn't receive adequate oxygen, potentially leading to:
- Brain damage
- Cerebral palsy
- Developmental disorders
- In severe cases, fetal death

### Current Problems
1. **Manual Analysis**: CTG interpretation is subjective and varies between medical professionals
2. **High False Positive Rates**: Leading to unnecessary cesarean sections
3. **Missed Detections**: Critical hypoxia cases may be overlooked
4. **Resource Intensive**: Requires experienced obstetricians for continuous monitoring

### Our Solution
This AI system provides:
- **Objective Analysis**: Consistent, bias-free interpretation of CTG patterns
- **Early Detection**: Identifies subtle patterns indicating developing hypoxia
- **Decision Support**: Assists medical professionals with evidence-based recommendations
- **24/7 Monitoring**: Automated continuous analysis capability

### File Structure Flow

```mermaid
graph TB
    A[HipoxiaDeepLearning/] --> B[Main Interfaces]
    A --> C[Core Modules]
    A --> D[Data Storage]
    A --> E[Method Implementations]

    B --> B1[main.py<br/>Interactive CLI]
    B --> B2[main_text.py<br/>Text-based CLI]

    C --> C1[generateDataset.py<br/>Data Preprocessing]
    C --> C2[fix_tensorflow.py<br/>Dependency Fixes]
    C --> C3[install_requirements.py<br/>Setup Automation]

    D --> D1[processed_data/<br/>Raw Signals]
    D --> D2[data/<br/>Method-Specific Data]
    D --> D3[models/<br/>Trained Models]
    D --> D4[results/<br/>Visualizations]

    E --> E1[methods/gan_method/<br/>CTGGAN Implementation]
    E --> E2[methods/mobilenet_method/<br/>MobileNet Implementation]
    E --> E3[methods/resnet_method/<br/>ResNet Implementation]

    E1 --> E1A[trainingWithGanMethod.py]
    E1 --> E1B[predictWithGanMethod.py]

    E2 --> E2A[trainingWithMobileNet.py]
    E2 --> E2B[predictWithMobileNet.py]

    E3 --> E3A[trainingWithResNet.py]
    E3 --> E3B[predictWithResNet.py]

    style B1 fill:#e3f2fd
    style B2 fill:#e3f2fd
    style E1 fill:#ffecb3
    style E2 fill:#e8f5e8
    style E3 fill:#e1f5fe
```

### Class Architecture Diagram

```mermaid
classDiagram
    class HipoxiaSystem {
        +initialize_system()
        +run_interactive_mode()
        +run_text_mode()
    }

    class DatasetGenerator {
        -base_path: str
        -signals_path: Path
        +load_clinical_data()
        +load_signal_data(record_id)
        +generate_unified_dataset()
        +prepare_data_for_training(method)
        +main()
    }

    class CTGGANTrainer {
        -signal_length: int
        -noise_dim: int
        -epochs: int
        +load_and_preprocess_data()
        +build_generator()
        +build_discriminator()
        +train(X_train, y_train)
        +build_classifier()
        +save_models()
    }

    class MobileNetTrainer {
        -spectrogram_shape: tuple
        -epochs: int
        -batch_size: int
        +load_and_preprocess_data()
        +build_mobilenet_model()
        +train_model(X_train, y_train, X_val, y_val)
        +evaluate_model(X_test, y_test)
        +save_training_plots()
    }

    class ResNetTrainer {
        -signal_length: int
        -num_classes: int
        -epochs: int
        +load_and_preprocess_data()
        +build_resnet1d_model()
        +residual_block_1d()
        +train_model(X_train, y_train, X_val, y_val)
        +evaluate_model(X_test, y_test)
    }

    class GANPredictor {
        -base_path: str
        -models_path: Path
        +load_models()
        +preprocess_signal(signal)
        +predict_record(record_id)
        +generate_visualizations()
    }

    class MobileNetPredictor {
        -base_path: str
        -model: Model
        +load_model()
        +signal_to_spectrogram()
        +predict_record(record_id)
        +create_prediction_plots()
    }

    class ResNetPredictor {
        -base_path: str
        -signal_length: int
        +load_model()
        +preprocess_signal()
        +predict_record(record_id)
        +visualize_prediction()
    }

    HipoxiaSystem --> DatasetGenerator
    HipoxiaSystem --> CTGGANTrainer
    HipoxiaSystem --> MobileNetTrainer
    HipoxiaSystem --> ResNetTrainer
    HipoxiaSystem --> GANPredictor
    HipoxiaSystem --> MobileNetPredictor
    HipoxiaSystem --> ResNetPredictor

    CTGGANTrainer --> GANPredictor : creates models
    MobileNetTrainer --> MobileNetPredictor : creates models
    ResNetTrainer --> ResNetPredictor : creates models

    DatasetGenerator --> CTGGANTrainer : provides data
    DatasetGenerator --> MobileNetTrainer : provides data
    DatasetGenerator --> ResNetTrainer : provides data
```

### Data Flow Between Components

```mermaid
sequenceDiagram
    participant User
    participant Interface as Main Interface
    participant DataGen as Dataset Generator
    participant Trainer as Model Trainer
    participant Predictor as Model Predictor
    participant Storage as File Storage

    User->>Interface: Start System
    Interface->>DataGen: Generate Dataset
    DataGen->>Storage: Save processed data
    DataGen-->>Interface: Dataset Ready

    User->>Interface: Train Model
    Interface->>Trainer: Initialize Training
    Trainer->>Storage: Load training data
    Storage-->>Trainer: Return data
    Trainer->>Trainer: Train neural network
    Trainer->>Storage: Save trained model
    Trainer-->>Interface: Training Complete

    User->>Interface: Make Prediction
    Interface->>Predictor: Predict record
    Predictor->>Storage: Load model & data
    Storage-->>Predictor: Return model & data
    Predictor->>Predictor: Process & classify
    Predictor->>Storage: Save visualizations
    Predictor-->>Interface: Return results
    Interface-->>User: Display prediction

    Note over User, Storage: Complete workflow from data to prediction
```

---

## ğŸ“Š Dataset Information

### Source Dataset
**CTU-UHB Intrapartum Cardiotocography Database**
- **Source**: https://physionet.org/content/ctu-uhb-ctgdb/1.0.0/
- **Institution**: Czech Technical University (CTU) and University Hospital in Brno (UHB)
- **Total Records**: 552 CTG recordings
- **Duration**: Variable length recordings (20 minutes to several hours)
- **Sampling Rate**: 4 Hz for FHR signals

### Dataset Characteristics
```
Original Dataset Statistics:
â”œâ”€â”€ Total Records: 552
â”œâ”€â”€ Record Range: 1001-2046
â”œâ”€â”€ Signal Types:
â”‚   â”œâ”€â”€ FHR (Fetal Heart Rate)
â”‚   â”œâ”€â”€ UC (Uterine Contractions)
â”‚   â””â”€â”€ Clinical annotations
â””â”€â”€ Labels based on umbilical cord pH:
    â”œâ”€â”€ Normal (pH â‰¥ 7.15): 375 records (67.9%)
    â”œâ”€â”€ Suspect (7.05 â‰¤ pH < 7.15): 121 records (21.9%)
    â””â”€â”€ Hypoxia (pH < 7.05): 56 records (10.1%)
```

### Clinical Significance
- **pH > 7.15**: Normal acid-base status
- **7.05 â‰¤ pH < 7.15**: Suspicious/intermediate condition
- **pH < 7.05**: Pathological acidosis indicating hypoxia

---

## ğŸ“ Project Structure

```
HipoxiaDeepLearning/
â”œâ”€â”€ ğŸ“‚ data/                          # Processed datasets
â”‚   â”œâ”€â”€ ğŸ“‚ gan/                       # GAN-specific preprocessed data
â”‚   â”œâ”€â”€ ğŸ“‚ mobilenet/                 # MobileNet-specific data (spectrograms)
â”‚   â”œâ”€â”€ ğŸ“‚ resnet/                    # ResNet-specific data (1D signals)
â”‚   â””â”€â”€ dataset_info.csv              # Unified dataset information
â”œâ”€â”€ ğŸ“‚ processed_data/                # Raw processed data
â”‚   â”œâ”€â”€ ğŸ“‚ signals/                   # Individual signal files (.npy)
â”‚   â””â”€â”€ mature_clinical_dataset.csv   # Clinical labels and metadata
â”œâ”€â”€ ğŸ“‚ methods/                       # Deep learning implementations
â”‚   â”œâ”€â”€ ğŸ“‚ gan_method/
â”‚   â”‚   â”œâ”€â”€ trainingWithGanMethod.py  # CTGGAN training
â”‚   â”‚   â””â”€â”€ predictWithGanMethod.py   # GAN predictions
â”‚   â”œâ”€â”€ ğŸ“‚ mobilenet_method/
â”‚   â”‚   â”œâ”€â”€ trainingWithMobileNet.py  # MobileNet training
â”‚   â”‚   â””â”€â”€ predictWithMobileNet.py   # MobileNet predictions
â”‚   â””â”€â”€ ğŸ“‚ resnet_method/
â”‚       â”œâ”€â”€ trainingWithResNet.py     # ResNet training
â”‚       â””â”€â”€ predictWithResNet.py      # ResNet predictions
â”œâ”€â”€ ğŸ“‚ models/                        # Trained model storage
â”‚   â”œâ”€â”€ ğŸ“‚ gan_models/               # GAN generator, discriminator, classifier
â”‚   â”œâ”€â”€ ğŸ“‚ mobilenet_models/         # MobileNet weights
â”‚   â””â”€â”€ ğŸ“‚ resnet_models/            # ResNet weights
â”œâ”€â”€ ğŸ“‚ results/                       # Training plots and results
â”‚   â””â”€â”€ ğŸ“‚ training_plots/           # Visualization outputs
â”œâ”€â”€ ğŸ main.py                       # Interactive CLI interface
â”œâ”€â”€ ğŸ main_text.py                  # Text-based interface (fallback)
â”œâ”€â”€ ğŸ generateDataset.py            # Dataset preprocessing pipeline
â”œâ”€â”€ ğŸ fix_tensorflow.py             # TensorFlow compatibility fix
â”œâ”€â”€ ğŸ install_requirements.py       # Automated dependency installer
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Full dependencies
â”œâ”€â”€ ğŸ“‹ requirements-minimal.txt      # Essential dependencies
â””â”€â”€ ğŸ“– README.md                     # This documentation
```

---

## ğŸ”„ System Flowcharts

### Overall System Architecture

```mermaid
graph TD
    A[CTG Record Input] --> B{Interface Selection}
    B -->|Interactive| C[main.py - Interactive CLI]
    B -->|Text-based| D[main_text.py - Text CLI]

    C --> E[Main Menu]
    D --> E

    E --> F{User Action}
    F -->|Generate Dataset| G[Dataset Processing]
    F -->|Train Models| H[Model Training]
    F -->|Predict| I[Prediction Analysis]
    F -->|System Info| J[Display Stats]

    G --> K[Load CTU-UHB Data]
    K --> L[Process 552 Records]
    L --> M[Create Method-Specific Data]
    M --> N[Save Dataset Files]

    H --> O{Select Method}
    O -->|GAN| P[CTGGAN Training]
    O -->|MobileNet| Q[MobileNet Training]
    O -->|ResNet| R[ResNet Training]

    P --> S[Save Trained Models]
    Q --> S
    R --> S

    I --> T{Select Method}
    T -->|GAN| U[GAN Prediction]
    T -->|MobileNet| V[MobileNet Prediction]
    T -->|ResNet| W[ResNet Prediction]

    U --> X[Generate Visualizations]
    V --> X
    W --> X

    X --> Y[Display Results]
    Y --> Z[Classification: Normal/Suspect/Hypoxia]
```

### Data Processing Pipeline

```mermaid
graph LR
    A[CTU-UHB Raw Data<br/>552 Records] --> B[Signal Extraction]
    B --> C[FHR Signal Processing<br/>4Hz Sampling]
    C --> D[Clinical Label Processing<br/>pH-based Classification]

    D --> E{Method-Specific<br/>Preprocessing}

    E -->|GAN Path| F[Signal Normalization<br/>Standard Length 5000]
    E -->|MobileNet Path| G[STFT Transform<br/>Spectrogram Generation]
    E -->|ResNet Path| H[1D Signal Processing<br/>Data Augmentation]

    F --> I[GAN Training Data<br/>Balance Classes]
    G --> J[Spectrograms<br/>224Ã—224Ã—3 RGB]
    H --> K[Augmented 1D Signals<br/>5000 points]

    I --> L[(data/gan/)]
    J --> M[(data/mobilenet/)]
    K --> N[(data/resnet/)]

    style A fill:#e1f5fe
    style L fill:#c8e6c9
    style M fill:#c8e6c9
    style N fill:#c8e6c9
```

### Training Workflow

```mermaid
graph TD
    A[Select Training Method] --> B{Method Choice}

    B -->|GAN| C[CTGGAN Training]
    B -->|MobileNet| D[MobileNet Training]
    B -->|ResNet| E[ResNet Training]

    C --> C1[Load Balanced Data]
    C1 --> C2[Train Generator<br/>Create Synthetic Signals]
    C2 --> C3[Train Discriminator<br/>Real vs Fake]
    C3 --> C4[Train Classifier<br/>3-Class Classification]
    C4 --> C5[Save Models<br/>Generator + Discriminator + Classifier]

    D --> D1[Load Spectrogram Data]
    D1 --> D2[Phase 1: Train Classification Head<br/>Frozen MobileNetV2]
    D2 --> D3[Phase 2: Fine-tune Top Layers<br/>Lower Learning Rate]
    D3 --> D4[Save MobileNet Model]

    E --> E1[Load 1D Signal Data]
    E1 --> E2[Apply Data Augmentation<br/>4x Dataset Size]
    E2 --> E3[Train Custom 1D ResNet<br/>Residual Connections]
    E3 --> E4[Save ResNet Model]

    C5 --> F[Training Complete<br/>Generate Plots]
    D4 --> F
    E4 --> F

    F --> G[Model Ready for Prediction]

    style C fill:#ffecb3
    style D fill:#e8f5e8
    style E fill:#e3f2fd
```

### Prediction Workflow

```mermaid
graph TD
    A[Enter Record Number<br/>1001-2046] --> B[Load Record Data]
    B --> C{Select Method}

    C -->|GAN| D[GAN Prediction Path]
    C -->|MobileNet| E[MobileNet Prediction Path]
    C -->|ResNet| F[ResNet Prediction Path]

    D --> D1[Load GAN Classifier]
    D1 --> D2[Preprocess Signal<br/>Normalize to 5000 points]
    D2 --> D3[Generate Prediction<br/>Classification Probabilities]

    E --> E1[Load MobileNet Model]
    E1 --> E2[Convert to Spectrogram<br/>224Ã—224Ã—3]
    E2 --> E3[MobileNet Inference<br/>Feature Extraction]

    F --> F1[Load ResNet Model]
    F1 --> F2[1D Signal Processing<br/>5000 points]
    F2 --> F3[ResNet Inference<br/>Residual Feature Learning]

    D3 --> G[Generate Visualizations]
    E3 --> G
    F3 --> G

    G --> H[Create Result Plots]
    H --> I[Signal Analysis Plots]
    H --> J[Feature Activation Maps]
    H --> K[Confidence Score Display]

    I --> L[Final Results Display]
    J --> L
    K --> L

    L --> M{Classification Result}
    M -->|pH â‰¥ 7.15| N[Normal<br/>Safe Delivery]
    M -->|7.05 â‰¤ pH < 7.15| O[Suspect<br/>Monitor Closely]
    M -->|pH < 7.05| P[Hypoxia<br/>Immediate Intervention]

    style N fill:#c8e6c9
    style O fill:#fff3e0
    style P fill:#ffcdd2
```

### Deep Learning Architecture Comparison

```mermaid
graph TD
    A[FHR Signal Input<br/>5000 points] --> B{Processing Path}

    B -->|GAN Method| C[Data Augmentation Path]
    B -->|MobileNet Method| D[Spectrogram Path]
    B -->|ResNet Method| E[1D CNN Path]

    C --> C1[CTGGAN Generator<br/>Noise + Label â†’ Synthetic Signal]
    C1 --> C2[Balanced Dataset<br/>375 samples per class]
    C2 --> C3[1D CNN Classifier<br/>Real + Synthetic Data]

    D --> D1[STFT Transform<br/>Time-Frequency Analysis]
    D1 --> D2[MobileNetV2 Backbone<br/>Pretrained ImageNet]
    D2 --> D3[Custom Classification Head<br/>Global Average Pooling]

    E --> E1[Direct 1D Processing<br/>No Frequency Transform]
    E1 --> E2[Custom ResNet Blocks<br/>Skip Connections]
    E2 --> E3[Multi-scale Feature Learning<br/>64â†’128â†’256â†’512 filters]

    C3 --> F[Classification Output]
    D3 --> F
    E3 --> F

    F --> G{Final Decision}
    G -->|Class 0| H[Normal<br/>Confidence Score]
    G -->|Class 1| I[Suspect<br/>Confidence Score]
    G -->|Class 2| J[Hypoxia<br/>Confidence Score]

    style C1 fill:#e1bee7
    style D2 fill:#c5e1a5
    style E2 fill:#b3e5fc
```

### Clinical Decision Support Flow

```mermaid
graph TD
    A[CTG Monitoring<br/>During Labor] --> B[FHR Signal Analysis]
    B --> C[AI System Processing<br/>Multi-Method Analysis]

    C --> D{Risk Assessment}

    D -->|Low Risk| E[Normal Classification<br/>pH â‰¥ 7.15]
    D -->|Medium Risk| F[Suspect Classification<br/>7.05 â‰¤ pH < 7.15]
    D -->|High Risk| G[Hypoxia Classification<br/>pH < 7.05]

    E --> E1[Continue Monitoring<br/>Standard Protocol]
    E1 --> E2[Regular Assessment<br/>Every 30 minutes]

    F --> F1[Enhanced Monitoring<br/>Increased Frequency]
    F1 --> F2[Consider Interventions<br/>Position Change, Oxygen]
    F2 --> F3[Re-evaluate in 15 minutes]

    G --> G1[Immediate Assessment<br/>Clinical Correlation]
    G1 --> G2[Emergency Interventions<br/>Consider Delivery]
    G2 --> G3[Multidisciplinary Team<br/>Obstetrician + Pediatrician]

    F3 --> H{Improvement?}
    H -->|Yes| E2
    H -->|No| G1

    E2 --> I[Continue Labor<br/>Natural Progression]
    G3 --> J[Rapid Delivery<br/>C-Section if Needed]

    style E fill:#c8e6c9
    style F fill:#fff3e0
    style G fill:#ffcdd2
    style J fill:#ff8a80
```

---

## ğŸ¤– Deep Learning Methods

### 1. CTGGAN Method (Data Augmentation + Classification)
**Purpose**: Address class imbalance and generate synthetic CTG patterns

**Architecture**:
```
Generator:
â”œâ”€â”€ Input: Noise (100D) + Class Label
â”œâ”€â”€ Label Embedding Layer (3 â†’ 50D)
â”œâ”€â”€ Dense Layer: 256Ã—125
â”œâ”€â”€ Residual Blocks with Self-Attention
â”œâ”€â”€ 1D Transposed Convolutions
â””â”€â”€ Output: Synthetic FHR Signal (5000 points)

Discriminator:
â”œâ”€â”€ Input: Real/Fake FHR Signal (5000D)
â”œâ”€â”€ 1D Convolutions with Batch Normalization
â”œâ”€â”€ Residual Connections
â”œâ”€â”€ Global Average Pooling
â””â”€â”€ Output: Real/Fake Classification

Classifier:
â”œâ”€â”€ Input: Combined Real + Generated Signals
â”œâ”€â”€ 1D CNN Feature Extraction
â”œâ”€â”€ Dense Layers with Dropout
â””â”€â”€ Output: 3-class Classification (Normal/Suspect/Hypoxia)
```

**Training Process**:
1. **GAN Training**: Generate synthetic signals to balance classes
2. **Data Augmentation**: Create balanced dataset (375 samples per class)
3. **Classifier Training**: Train on combined real + synthetic data

### 2. MobileNet Method (Lightweight CNN)
**Purpose**: Efficient deployment with spectrogram-based analysis

**Data Preprocessing**:
```python
FHR Signal â†’ Short-Time Fourier Transform â†’ Spectrogram (224Ã—224Ã—3) â†’ MobileNet
```

**Architecture**:
```
Base Model: MobileNetV2 (ImageNet pretrained)
â”œâ”€â”€ Input: Spectrogram (224Ã—224Ã—3)
â”œâ”€â”€ Feature Extraction: MobileNetV2 backbone (frozen)
â”œâ”€â”€ Global Average Pooling
â”œâ”€â”€ Dense Layer (128 neurons, ReLU)
â”œâ”€â”€ Dropout (0.5)
â””â”€â”€ Output: 3-class Softmax

Training Strategy:
â”œâ”€â”€ Phase 1: Train classification head (frozen backbone)
â”œâ”€â”€ Phase 2: Fine-tune top 30 layers (lower learning rate)
```

**Advantages**:
- Fast inference (~10-50ms per prediction)
- Small model size (~9MB)
- Suitable for mobile/edge deployment

### 3. ResNet Method (Deep Residual Network)
**Purpose**: High accuracy with direct 1D signal processing

**Architecture**:
```
Custom 1D ResNet:
â”œâ”€â”€ Input: FHR Signal (5000 points)
â”œâ”€â”€ Initial Convolution (64 filters)
â”œâ”€â”€ Residual Block 1: 64 filters
â”œâ”€â”€ Residual Block 2: 128 filters
â”œâ”€â”€ Residual Block 3: 256 filters
â”œâ”€â”€ Residual Block 4: 512 filters
â”œâ”€â”€ Global Average Pooling
â”œâ”€â”€ Dense Layer (256 neurons)
â”œâ”€â”€ Dropout (0.5)
â””â”€â”€ Output: 3-class Classification

Residual Block Structure:
â”œâ”€â”€ Conv1D + BatchNorm + ReLU
â”œâ”€â”€ Conv1D + BatchNorm
â”œâ”€â”€ Skip Connection
â””â”€â”€ ReLU Activation
```

**Data Augmentation**:
- Gaussian noise addition
- Signal stretching/compression
- Amplitude scaling
- Random cropping

---

## ğŸ”„ Data Pipeline

### Stage 1: Raw Data Processing
```
CTU-UHB Raw Data (.dat files)
           â†“
Signal Extraction & Preprocessing
â”œâ”€â”€ FHR signal cleaning
â”œâ”€â”€ Resampling to 4Hz
â”œâ”€â”€ Artifact removal
â””â”€â”€ Signal standardization
           â†“
Individual Signal Files (.npy)
```

### Stage 2: Clinical Label Processing
```
Clinical Annotations
           â†“
pH-based Classification
â”œâ”€â”€ pH â‰¥ 7.15 â†’ Normal (0)
â”œâ”€â”€ 7.05 â‰¤ pH < 7.15 â†’ Suspect (1)
â””â”€â”€ pH < 7.05 â†’ Hypoxia (2)
           â†“
mature_clinical_dataset.csv
```

### Stage 3: Method-Specific Preprocessing

#### GAN Method Pipeline:
```
Raw FHR Signals â†’ Normalization â†’ Standard Length (5000) â†’ GAN Training Data
```

#### MobileNet Pipeline:
```
Raw FHR Signals â†’ STFT â†’ Spectrogram â†’ Resize (224Ã—224) â†’ RGB Conversion â†’ MobileNet Data
```

#### ResNet Pipeline:
```
Raw FHR Signals â†’ Normalization â†’ Standard Length (5000) â†’ Data Augmentation â†’ ResNet Data
```

### Stage 4: Dataset Organization
```
Final Dataset Structure:
â”œâ”€â”€ data/gan/X_data.npy (5000D signals)
â”œâ”€â”€ data/mobilenet/X_data.npy (224Ã—224Ã—3 spectrograms)
â”œâ”€â”€ data/resnet/X_data.npy (5000D signals)
â””â”€â”€ Shared: y_data.npy, record_ids.npy
```

---

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- GPU with CUDA support (optional but recommended)
- 8GB RAM minimum
- 10GB free disk space

### Quick Installation

```bash
# Clone the repository
git clone <repository-url>
cd HipoxiaDeepLearning

# Automated installation
python3 install_requirements.py

# Or manual installation
pip install -r requirements.txt
```

### Dependency Resolution
If you encounter TensorFlow conflicts:
```bash
python3 fix_tensorflow.py
```

### Verify Installation
```bash
python3 main_text.py
# Should show system information without errors
```

---

## ğŸš€ Usage

### Interactive Interface (Recommended)
```bash
python3 main.py
```

### Text-Based Interface (Terminal compatible)
```bash
python3 main_text.py
```

### System Workflow

#### 1. Dataset Generation
```
Main Menu â†’ Generate Dataset
â”œâ”€â”€ Processes 552 CTG records
â”œâ”€â”€ Creates method-specific datasets
â””â”€â”€ Generates dataset_info.csv
```

#### 2. Model Training
```
Main Menu â†’ Train Models â†’ Select Method
â”œâ”€â”€ GAN Method: ~5-10 minutes training
â”œâ”€â”€ MobileNet: ~3-5 minutes training
â””â”€â”€ ResNet: ~10-15 minutes training
```

#### 3. Prediction
```
Main Menu â†’ Predict â†’ Select Method â†’ Enter Record Number
â”œâ”€â”€ Input: Record ID (1001-2046)
â”œâ”€â”€ Processing: Signal analysis
â””â”€â”€ Output: Classification + Visualizations
```

### Example Prediction Workflow
```bash
# 1. Start system
python3 main_text.py

# 2. Select "Predict with Models"
# 3. Choose method (e.g., ResNet)
# 4. Enter record number (e.g., 1001)
# 5. View results:
#    - Classification: Normal/Suspect/Hypoxia
#    - Confidence scores
#    - Signal visualization
#    - Feature analysis plots
```

---

## âš™ï¸ System Features

### Input Requirements
- **Single Input**: CTG record number (1001-2046)
- **No preprocessing needed**: System handles all data preparation

### Output Comprehensive Analysis
- **Classification Result**: Normal, Suspect, or Hypoxia
- **Confidence Scores**: Probability for each class
- **Signal Visualization**: FHR pattern plots
- **Feature Analysis**: Method-specific feature maps
- **Clinical Context**: Record metadata and statistics

### Visual Outputs Generated

#### GAN Method Outputs:
- Generated vs Real signal comparison
- Training loss curves (Generator/Discriminator)
- Classification confidence visualization
- Data augmentation effectiveness plots

#### MobileNet Outputs:
- Original signal and corresponding spectrogram
- Feature activation maps
- Training history (accuracy/loss curves)
- Confusion matrix on test set

#### ResNet Outputs:
- Signal preprocessing steps
- Residual block activations
- Training metrics visualization
- Per-class performance analysis

### Interface Options

#### 1. Interactive CLI (`main.py`)
- **Features**: Arrow key navigation, visual menus
- **Best for**: Interactive exploration and analysis
- **Requirements**: Terminal with full TTY support

#### 2. Text-Based CLI (`main_text.py`)
- **Features**: Number-based menu selection
- **Best for**: Script automation, limited terminals
- **Requirements**: Basic terminal support

---

## ğŸ—ï¸ Technical Architecture

### System Design Principles
- **Modularity**: Each method is independently implementable
- **Scalability**: Easy to add new methods or modify existing ones
- **Maintainability**: Clean separation of concerns
- **Reproducibility**: Fixed random seeds and consistent preprocessing

### Performance Optimizations
- **Memory Management**: Lazy loading and efficient data structures
- **GPU Utilization**: Automatic GPU detection and usage
- **Batch Processing**: Optimized batch sizes for training/inference
- **Model Checkpointing**: Save/resume training capability

### Error Handling
- **Graceful Degradation**: Fallback options for various error scenarios
- **User Feedback**: Clear error messages and suggested solutions
- **Recovery Mechanisms**: Automatic retry and alternative approaches

---

## ğŸ“ˆ Results and Performance

### Classification Performance

```
Method Comparison (1 epoch training - demo mode):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method       â”‚ Accuracy â”‚ Precision â”‚ Recall  â”‚ Training Time   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GAN Method   â”‚  ~65%    â”‚   ~45%    â”‚  ~65%   â”‚  ~5 minutes     â”‚
â”‚ MobileNet    â”‚  ~69%    â”‚   ~47%    â”‚  ~69%   â”‚  ~3 minutes     â”‚
â”‚ ResNet       â”‚  ~69%    â”‚   ~47%    â”‚  ~69%   â”‚  ~10 minutes    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*Note: Results shown are from 1-epoch training for demonstration. Full training would require 50-100 epochs for optimal performance.*

### Class-Specific Performance
```
Normal Class (pH â‰¥ 7.15):
â”œâ”€â”€ High recall (~80-90%) - Good at identifying normal cases
â””â”€â”€ Lower precision due to class imbalance correction

Suspect Class (7.05 â‰¤ pH < 7.15):
â”œâ”€â”€ Moderate performance (~60-70%)
â””â”€â”€ Most challenging due to boundary classification

Hypoxia Class (pH < 7.05):
â”œâ”€â”€ Critical class - prioritized for high recall
â””â”€â”€ Better precision after GAN augmentation
```

### Computational Requirements

```
Training Requirements:
â”œâ”€â”€ GPU Memory: 4-8GB recommended
â”œâ”€â”€ Training Time: 30 minutes - 2 hours (full training)
â””â”€â”€ Storage: ~2GB for models and results

Inference Requirements:
â”œâ”€â”€ CPU: Any modern processor
â”œâ”€â”€ Memory: 2-4GB RAM
â”œâ”€â”€ Response Time: <1 second per prediction
â””â”€â”€ Model Size: 10-200MB depending on method
```

---

## ğŸ”§ Development Guide

### Adding New Methods

1. **Create Method Directory**:
```bash
mkdir methods/new_method
```

2. **Implement Required Files**:
```python
# methods/new_method/trainingWithNewMethod.py
class NewMethodTrainer:
    def __init__(self, base_path):
        # Initialize trainer
        pass

    def load_and_preprocess_data(self):
        # Load data specific to your method
        pass

    def build_model(self):
        # Build your model architecture
        pass

    def train_model(self, X_train, y_train, X_val, y_val):
        # Training logic
        pass

    def evaluate_model(self, X_test, y_test):
        # Evaluation and metrics
        pass

# methods/new_method/predictWithNewMethod.py
class NewMethodPredictor:
    def predict_record(self, record_id):
        # Prediction logic
        pass
```

3. **Update Main Interface**:
```python
# Add to main.py and main_text.py
from methods.new_method.trainingWithNewMethod import NewMethodTrainer
from methods.new_method.predictWithNewMethod import NewMethodPredictor
```

### Customizing Preprocessing

```python
# In generateDataset.py
def prepare_data_for_training(self, method='new_method'):
    if method == 'new_method':
        # Implement your preprocessing
        return processed_X, processed_y, record_ids
```

### Model Architecture Guidelines

```python
# Standard model structure
class YourModel:
    def __init__(self):
        self.signal_length = 5000  # Standardized
        self.num_classes = 3       # Normal, Suspect, Hypoxia
        self.epochs = 1           # Set for quick demo

    def compile_model(self):
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']  # Keep simple for compatibility
        )
```

### Testing New Methods

```python
# Create test script
def test_new_method():
    trainer = NewMethodTrainer()

    # Test data loading
    X, y = trainer.load_and_preprocess_data()
    assert X.shape[0] == 552

    # Test model building
    model = trainer.build_model()
    assert model is not None

    print("âœ… New method tests passed!")

if __name__ == "__main__":
    test_new_method()
```

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. TensorFlow Version Conflicts
```bash
# Symptom: SymbolAlreadyExposedError
# Solution:
python3 fix_tensorflow.py
```

#### 2. Terminal Compatibility Issues
```bash
# Symptom: termios.error: Inappropriate ioctl for device
# Solution: Use text-based interface
python3 main_text.py
```

#### 3. Memory Issues During Training
```bash
# Symptom: OOM errors
# Solution: Reduce batch size in training methods
# Edit methods/*/training*.py and reduce self.batch_size
```

#### 4. Missing Dataset
```bash
# Symptom: FileNotFoundError for dataset files
# Solution: Run dataset generation first
python3 main_text.py â†’ Select "Generate Dataset"
```

#### 5. CUDA/GPU Issues
```bash
# Symptom: GPU not detected or CUDA errors
# Solution: Set CPU-only mode
export CUDA_VISIBLE_DEVICES=""
```

### Performance Optimization

#### Speed Up Training
```python
# Reduce epochs for testing (already set to 1)
# In methods/*/training*.py:
self.epochs = 1  # For demo/testing

# For full training:
self.epochs = 50  # MobileNet
self.epochs = 100  # ResNet/GAN
```

#### Memory Optimization
```python
# Reduce batch size
self.batch_size = 16  # Instead of 32

# Use mixed precision (advanced)
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy(policy)
```

### Debug Mode
```python
# Enable verbose logging
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ğŸ¤ Contributing

### Development Setup
```bash
git clone <repository-url>
cd HipoxiaDeepLearning
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Code Style Guidelines
- Follow PEP 8 for Python code style
- Use descriptive variable names
- Add docstrings for all functions
- Include type hints where appropriate
- Keep functions focused and modular

### Testing Guidelines
- Test with single epoch training (current setup)
- Verify all three methods work end-to-end
- Test both interface modes
- Check visualization generation
- Validate prediction outputs

### Pull Request Process
1. Fork the repository
2. Create feature branch
3. Make changes with tests
4. Update documentation
5. Submit pull request

---

## ğŸ“š References

### Primary Dataset
- **ChudÃ¡Äek, V., Spilka, J., BurÅ¡a, M., JankÅ¯, P., Hruban, L., Huptych, M., & LhotskÃ¡, L.** (2014). Open access intrapartum CTG database. *BMC pregnancy and childbirth*, 14(1), 16.

### Research Papers
- **CTGGAN**: Conditional Tabular GAN for CTG data augmentation
- **MobileNets**: Howard, A. G., et al. "MobileNets: Efficient convolutional neural networks for mobile vision applications."
- **ResNet**: He, K., et al. "Deep residual learning for image recognition."

### Clinical Guidelines
- **FIGO Guidelines** on intrapartum fetal monitoring
- **ACOG Practice Bulletin** on antepartum fetal surveillance
- **NICE Guidelines** on fetal monitoring during labour

### Technical Resources
- **TensorFlow Documentation**: https://tensorflow.org/
- **Keras API Reference**: https://keras.io/
- **PhysioNet Database**: https://physionet.org/

---

## ğŸ“„ License

This project is developed for educational and research purposes. Please refer to the dataset license for specific usage terms.

## ğŸ“§ Contact

For questions, issues, or contributions, please create an issue in the project repository.

---

**ğŸ”¬ Advancing Fetal Healthcare with AI** ğŸš€

*This system represents a significant step forward in automated fetal monitoring, providing medical professionals with powerful tools for early detection and intervention in cases of fetal hypoxia.*